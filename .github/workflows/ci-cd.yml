name: CI/CD Pipeline

on:
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  manage-certificates:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      - name: Install OpenSSL
        run: |
          sudo apt-get update
          sudo apt-get install -y openssl
      - name: Manage SSL Certificates
        run: ./scripts/manage-certificates.sh
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
  version:
    needs: manage-certificates
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.bump.outputs.new_version }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history and tags!
      - name: Bump version
        id: bump
        run: |
          git fetch --tags
          latest=$(git tag --list 'v*' --sort=-v:refname | head -n1)
          if [ -z "$latest" ]; then
            latest="v0.0.0"
          fi
          echo "Latest tag: $latest"
          IFS='.' read -r major minor patch <<< "${latest#v}"
          if git log -1 --pretty=%B | grep -qE "fix:"; then
            patch=$((patch+1))
          elif git log -1 --pretty=%B | grep -qE "feat:"; then
            minor=$((minor+1)); patch=0
          else
            patch=$((patch+1))
          fi
          new_tag="v${major}.${minor}.${patch}"
          if git rev-parse "$new_tag" >/dev/null 2>&1; then
            echo "Tag $new_tag already exists. Skipping tag creation."
          else
            git tag $new_tag
            git push origin $new_tag
          fi
          echo "::set-output name=new_version::$new_tag"
  build-and-push:
    needs: version
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Build and push image
        uses: docker/build-push-action@v3
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKERHUB_USERNAME }}/barkuni-api:${{ needs.version.outputs.version }}
            ${{ secrets.DOCKERHUB_USERNAME }}/barkuni-api:latest
          platforms: linux/amd64,linux/arm64
  deploy-all:
    needs: [build-and-push, manage-certificates]
    runs-on: ubuntu-latest
    container:
      image: muzaparoff/terraform-runner:latest
      options: --platform=linux/amd64
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1
      CLUSTER_NAME: barkuni-eks
    steps:
      - uses: actions/checkout@v4
      - name: Terraform Init and Import (Infra)
        run: |
          cd terraform
          terraform init -backend=false
          # (Optional: Import existing resources if needed)
      - name: Terraform Apply (Infra)
        run: |
          cd terraform
          terraform apply -auto-approve -target=aws_eks_cluster.main -target=aws_eks_node_group.general
      - name: Wait for EKS Cluster and Node Group
        run: |
          for i in {1..30}; do 
            STATUS=$(aws eks describe-cluster --name $CLUSTER_NAME --region $AWS_DEFAULT_REGION --query "cluster.status" --output text)
            echo "EKS cluster status: $STATUS"
            if [ "$STATUS" = "ACTIVE" ]; then break; fi
            sleep 20; 
          done
          for i in {1..30}; do 
            STATUS=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name general --region $AWS_DEFAULT_REGION --query "nodegroup.status" --output text)
            echo "Node group status: $STATUS"
            if [ "$STATUS" = "ACTIVE" ]; then break; fi
            sleep 20; 
          done
      - name: Configure Kubectl & Create Namespace
        run: |
          aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_DEFAULT_REGION
          kubectl get nodes
          kubectl get namespace barkuni || kubectl create namespace barkuni
      - name: Create/Update TLS Secret
        run: |
          kubectl create secret tls barkuni-tls --cert=./certs/tls.crt --key=./certs/tls.key --namespace barkuni || true
      - name: Install Helm & Deploy Application
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm upgrade --install barkuni-api ./helm/barkuni-api \
            --namespace barkuni \
            --set serviceAccount.name=barkuni-api-sa \
            --set serviceAccount.create=true \
            --set persistence.size=8Gi \
            --set persistence.accessModes={ReadWriteOnce} \
            --set persistence.storageClass=gp2 \
            --set persistence.enabled=true \
            --set autoscaling.targetCPUUtilizationPercentage=50 \
            --set autoscaling.maxReplicas=10 \
            --set autoscaling.minReplicas=2 \
            --set autoscaling.enabled=true \
            --set resources.requests.memory=256Mi \
            --set resources.requests.cpu=250m \
            --set resources.limits.memory=512Mi \
            --set resources.limits.cpu=500m \
            --set env.PORT=8000 \
            --set env.NODE_ENV=production \
            --set service.name=barkuni-api \
            --set service.targetPort=8000 \
            --set service.port=80 \
            --set service.type=ClusterIP \
            --set image.pullPolicy=IfNotPresent \
            --set image.repository=${{ secrets.DOCKERHUB_USERNAME }}/barkuni-api \
            --set image.tag=${{ needs.build-and-push.outputs.tags }} \
            --wait --timeout 5m
      - name: Install NGINX Ingress Controller
        run: |
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx --create-namespace \
            --set controller.publishService.enabled=true
      - name: Get NGINX Ingress LB DNS Name
        id: nginx_lb
        run: |
          for i in {1..30}; do
            LB_DNS=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            if [ -n "$LB_DNS" ]; then
              echo "nginx_lb_dns_name=$LB_DNS" >> $GITHUB_OUTPUT
              break
            fi
            echo "Waiting for NGINX Ingress LB DNS name..."
            sleep 10
          done
          if [ -z "$LB_DNS" ]; then
            echo "ERROR: NGINX Ingress LoadBalancer DNS name not found." >&2
            exit 1
          fi
      - name: Terraform Apply (DNS)
        run: |
          cd terraform
          echo "nginx_lb_dns_name=${{ steps.nginx_lb.outputs.nginx_lb_dns_name }}"
          terraform apply -auto-approve -target=aws_route53_record.nginx_ingress -var="nginx_lb_dns_name=${{ steps.nginx_lb.outputs.nginx_lb_dns_name }}"
        env:
          nginx_lb_dns_name: ${{ steps.nginx_lb.outputs.nginx_lb_dns_name }}